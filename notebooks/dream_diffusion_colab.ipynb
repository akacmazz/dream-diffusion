{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DREAM Diffusion - High-Quality Face Generation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/dream-diffusion/blob/main/notebooks/dream_diffusion_colab.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue)](https://github.com/yourusername/dream-diffusion)\n",
    "\n",
    "This notebook implements **DREAM (Diffusion Rectification and Estimation-Adaptive Models)** for face generation using the CelebA dataset.\n",
    "\n",
    "## Key Features:\n",
    "- üöÄ **DREAM Framework**: Advanced diffusion training with rectification loss\n",
    "- üõ°Ô∏è **Crash Protection**: Auto-recovery training with checkpoint management\n",
    "- ‚ö° **Memory Optimized**: Efficient for consumer GPUs (RTX 3070+)\n",
    "- üìä **Comprehensive Evaluation**: FID, Inception Score, visual metrics\n",
    "- üîß **Conservative Settings**: Stable hyperparameters for reproducible results\n",
    "\n",
    "## Usage Instructions:\n",
    "1. **Run cells in order** - Each cell is numbered and contains specific functionality\n",
    "2. **Automatic dataset download** - CelebA will be downloaded automatically\n",
    "3. **Crash protection** - Training will auto-resume from checkpoints\n",
    "4. **Memory management** - Optimized for 8GB+ GPU memory\n",
    "\n",
    "## Expected Results:\n",
    "- **Training Time**: ~14-20 hours on Tesla V100/A100\n",
    "- **FID Score**: Expected < 30 (lower is better)\n",
    "- **Inception Score**: Expected > 2.5 (higher is better)\n",
    "- **Sample Quality**: High-resolution 64√ó64 face generation\n",
    "\n",
    "---\n",
    "**Note**: This is a research implementation. For production use, please see the [GitHub repository](https://github.com/yourusername/dream-diffusion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: GPU Setup and Environment Check\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Keep Alive Function for longer training sessions\n",
    "def keep_alive():\n",
    "    \"\"\"Keeps Colab session active during training\"\"\"\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f\"üì° Session active: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ GPU setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive and Setup Directories\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Create project directories\n",
    "project_dir = '/content/drive/MyDrive/dream_diffusion'\n",
    "checkpoint_dir = f'{project_dir}/checkpoints'\n",
    "output_dir = f'{project_dir}/outputs'\n",
    "eval_dir = f'{project_dir}/evaluation'\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "# Check for existing checkpoints (crash recovery)\n",
    "latest_checkpoint = os.path.join(checkpoint_dir, 'latest.pt')\n",
    "if os.path.exists(latest_checkpoint):\n",
    "    print(\"üîÑ CRASH RECOVERY: Previous training found!\")\n",
    "    checkpoint_info = torch.load(latest_checkpoint, map_location='cpu', weights_only=False)\n",
    "    print(f\"üìä Last epoch: {checkpoint_info.get('epoch', 'Unknown')}\")\n",
    "    print(f\"üìä Last loss: {checkpoint_info.get('loss', 'Unknown'):.4f}\")\n",
    "    print(\"‚ö†Ô∏è  Training will resume automatically\")\n",
    "else:\n",
    "    print(\"üÜï Fresh start - no previous training found\")\n",
    "\n",
    "print(\"‚úÖ Directory setup complete!\")\n",
    "print(f\"üìÅ Checkpoints: {checkpoint_dir}\")\n",
    "print(f\"üìÅ Outputs: {output_dir}\")\n",
    "print(f\"üìÅ Evaluation: {eval_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Install Required Packages\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "!pip install -q einops accelerate tensorboard\n",
    "!pip install -q torch-fidelity clean-fid lpips scipy\n",
    "!pip install -q gdown  # For dataset download\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")\n",
    "print(\"üìä Evaluation tools ready: FID, IS, LPIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Download and Verification\n",
    "dataset_path = '/content/img_align_celeba'\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    num_images = len([f for f in os.listdir(dataset_path) if f.endswith('.jpg')])\n",
    "    print(f\"‚úÖ Dataset already exists: {num_images:,} images\")\n",
    "else:\n",
    "    print(\"üì• Downloading CelebA dataset...\")\n",
    "    !gdown --id 1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684 -O celeba.zip\n",
    "    print(\"üìÇ Extracting dataset...\")\n",
    "    !unzip -q celeba.zip -d /content/\n",
    "    !rm celeba.zip\n",
    "\n",
    "    if os.path.exists(dataset_path):\n",
    "        num_images = len([f for f in os.listdir(dataset_path) if f.endswith('.jpg')])\n",
    "        print(f\"‚úÖ Dataset ready: {num_images:,} images\")\n",
    "    else:\n",
    "        print(\"‚ùå Dataset download failed!\")\n",
    "        raise Exception(\"Please check your internet connection and try again\")\n",
    "\n",
    "# Check available disk space\n",
    "!df -h /content\n",
    "print(\"üíæ Disk space check complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Session Keep-Alive (Anti-Disconnect)\n",
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "# JavaScript code to keep session alive\n",
    "js_code = \"\"\"\n",
    "// Auto-clicker for Colab (Prevents timeout)\n",
    "function ClickConnect(){\n",
    "    console.log(\"üîÑ Keeping session alive...\");\n",
    "    var connectButton = document.querySelector(\"colab-connect-button\");\n",
    "    if (connectButton) {\n",
    "        connectButton.click();\n",
    "    }\n",
    "}\n",
    "\n",
    "// Run every 60 seconds\n",
    "var keepAliveInterval = setInterval(ClickConnect, 60000);\n",
    "console.log(\"üöÄ Auto-clicker started - Session will stay alive!\");\n",
    "\n",
    "// To stop manually: clearInterval(keepAliveInterval)\n",
    "\"\"\"\n",
    "\n",
    "display(Javascript(js_code))\n",
    "\n",
    "print(\"üöÄ Auto-clicker started!\")\n",
    "print(\"üì° Session crash protection active\")\n",
    "print(\"‚ö†Ô∏è  This will prevent Colab from disconnecting during training\")\n",
    "print(\"\\nüí° To stop manually, run: clearInterval(keepAliveInterval) in browser console\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}